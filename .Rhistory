janitor::clean_names()
var_list <- list(
Housing = structure(list(
MGT_477 = structure("MGT-477", stselected=FALSE, sttype="default", sticon="file"),
MGT_472 = structure("MGT-472", stselected=FALSE, sttype="default", sticon="file")
), stselected=FALSE, sttype="default", sticon="file"),
Mass_Care = structure(list(
MGT_487 = structure("MGT-487", stselected=FALSE, sttype="default", sticon="file"),
PER_406 = structure("PER-406", stselected=FALSE, sttype="default", sticon="file")
), stselected=FALSE, sttype="default", sticon="file"),
Pandemic_Preparedness = structure(list(
MGT_488 = structure("MGT-488", stselected=FALSE, sttype="default", sticon="file"),
PER_409 = structure("PER-409", stselected=FALSE, sttype="default", sticon="file")
), stselected=FALSE, sttype="default", sticon="file"),
Climate_Equity = structure(list(
MGT_491 = structure("MGT-491", stselected=FALSE, sttype="default", sticon="file"),
PER_420 = structure("PER-420", stselected=FALSE, sttype="default", sticon="file")
), stselected=FALSE, sttype="default", sticon="file")
)
# us map data
us_spdf <- rgdal::readOGR(
dsn= "data/cb_2018_us_state_20m",
verbose=FALSE
)
View(state_name)
View(dat)
?left_join()
dat_2 <- dat |>
left_join(state_name,by ="states", "state_2")
dat_2 <- dat |>
left_join(state_name,by = "state_2", "states")
dat_2 <- dat |>
right_join(state_name,by = "state_2", "states")
dat_2 <- dat |>
left_join(state_name,by = c("states"= "state_2"))
View(dat)
View(dat)
View(dat_2)
dat <- dat |>
left_join(state_name,by = c("states"= "state_2"))
dat <- dat |>
left_join(state_name,by = c("states"= "state_2"))
View(dat)
# load data
source("Data Cleaning.R") # source the data from the cleaned app
library(rgdal)
library(tidyverse)
library(leaflet)
library(RColorBrewer)
library(DT)
library(shinyTree)
library(shinyWidgets)
# load data
source("Data Cleaning.R") # source the data from the cleaned app
View(df_s)
dat <- df_s |>
group_by(states) |>
mutate(n_course_state = sum(n_each_course_state)) |>
mutate(state_n = paste(states, "<br/>", "<br/>",
"(Total Number of Training = ",
n_course_state,
")",
sep = ""))
state_name <- openxlsx::read.xlsx("data/States_codes_regions.xlsx") |>
janitor::clean_names()
dat <- dat |>
left_join(state_name,by = c("states"= "state_2"))
View(dat)
View(dat)
remove(dat)
dat <- df_s |>
group_by(states) |>
mutate(n_course_state = sum(n_each_course_state)) |>
mutate(state_n = paste(states, "<br/>", "<br/>",
"(Total Number of Training = ",
n_course_state,
")",
sep = ""))
View(dat)
state_name <- openxlsx::read.xlsx("data/States_codes_regions.xlsx") |>
janitor::clean_names()
dat <- dat |>
left_join(state_name,by = c("states"= "state_2")) |>
group_by(region) |>
mutate(n_course_region = sum(n_each_course_state))
View(dat)
shiny::runApp()
View(dat)
runApp()
install.packages("plotly")
library(plotly)
runApp()
runApp()
runApp()
runApp()
runApp()
# Filter data based on selected courses from the tree
# selected_course <- unlist(input$tree) # Extract selected courses
selected_course <- c("MGT-477", "MGT-472")
print(selected_course) # Debugging line
if(length(selected_course) > 0){
dat_filtered <- dat %>%
filter(training %in% selected_course)
print(dat_filtered) # Debugging line
plot_data <- dat_filtered %>%
group_by(region, training) %>%
summarize(total_courses = sum(n_each_course_state)) %>%
ungroup()
print(plot_data) # Debugging line
plot_ly(data = plot_data,
x = ~region,
y = ~total_courses,
color = ~training,
type = "bar",
colors = RColorBrewer::brewer.pal(n=length(unique(dat_filtered$training)), name="Set1")) %>%
layout(barmode = "stack")
} else {
plot_ly(type = "bar") # Empty chart
}
# Filter data based on selected courses from the tree
# selected_course <- unlist(input$tree) # Extract selected courses
selected_course <- c("MGT-477")
print(selected_course) # Debugging line
if(length(selected_course) > 0){
dat_filtered <- dat %>%
filter(training %in% selected_course)
print(dat_filtered) # Debugging line
plot_data <- dat_filtered %>%
group_by(region, training) %>%
summarize(total_courses = sum(n_each_course_state)) %>%
ungroup()
print(plot_data) # Debugging line
plot_ly(data = plot_data,
x = ~region,
y = ~total_courses,
color = ~training,
type = "bar",
colors = RColorBrewer::brewer.pal(n=length(unique(dat_filtered$training)), name="Set1")) %>%
layout(barmode = "stack")
} else {
plot_ly(type = "bar") # Empty chart
}
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
# Import google sheet data and get authorization --------------------------
#gs4_auth() # get authentication
sheet <- read("data/Instructor-led Trainings Scheduling & Outreach - Scheduling.csv") %>%
janitor::clean_names()
#library(googlesheets4) # package to interface with google sheets
library(dplyr)
# Import google sheet data and get authorization --------------------------
#gs4_auth() # get authentication
sheet <- read("data/Instructor-led Trainings Scheduling & Outreach - Scheduling.csv") %>%
janitor::clean_names()
# Import google sheet data and get authorization --------------------------
#gs4_auth() # get authentication
sheet <- read.csv("data/Instructor-led Trainings Scheduling & Outreach - Scheduling.csv") %>%
janitor::clean_names()
View(sheet)
shiny::runApp()
runApp()
# Import google sheet data and get authorization --------------------------
#gs4_auth() # get authentication
sheet <- read.csv("data/Instructor-led Trainings Scheduling & Outreach - Scheduling.csv") %>%
janitor::clean_names()
View(sheet)
# unlist all cells
sheet_unlisted <- as.data.frame(sapply(sheet, function(col) {
sapply(col, function(cell) {
if(length(cell) > 0) cell[[1]] else NA
})
})) # The outer sapply iterates over the columns of the data frame df.
col_index <- which(sheet_unlisted[1, ] == "REMAINING")[1] # see where the word "remaining" is
sheet_selected <- sheet_unlisted %>%
select(1:(col_index-1)) %>%  # select needed columns
filter(row_number() < which(training == "TOTAL")[1]) #select needed rows
## generate new column name based on the first row
new_col_name <- sapply(1:ncol(sheet_selected), function(i) {
val <- sheet_selected[1,i]
# Check for NA values
if (is.na(val)) {
return(names(sheet_selected)[i])
}
# Check for numbers from 1 to 10
if (str_detect(val, "^([1-9]|10)$")) {
return(paste0("region ", val))
} else {
return(names(sheet_selected)[i])
}
}) # if the row is number from 1-10 then use the number, otherwise copy the column name
colnames(sheet_selected) <- new_col_name
df_plotting <- sheet_selected %>%
slice(-1) %>% # remove the first row of the dataset
select("training", starts_with("region")) %>% # select training and region data
fill(!!names(sheet_selected)[1], .direction = "down") %>% #To fill NA values in the first column with the value from the row above
filter(str_detect(as.character(.[[1]]), "[0-9]"))
df_s <- df_plotting %>%
pivot_longer(cols = starts_with("region"),
names_to = "region",
values_to = "states"
)
df_s <- df_s %>%
select(training, states) %>%
na.omit() %>%
group_by(training, states) %>%
summarise(n_each_course_state = n())
View(df_s)
# Import google sheet data and get authorization --------------------------
gs4_auth() # get authentication
library(googlesheets4) # package to interface with google sheets
# Import google sheet data and get authorization --------------------------
gs4_auth() # get authentication
sheet <- sheet("https://docs.google.com/spreadsheets/d/1MJDXdoWOK-sEFnCqOtdVlbB0XcQGF32-8iGKS8UvmjE/edit") %>%
janitor::clean_names()
sheet <- sheets("https://docs.google.com/spreadsheets/d/1MJDXdoWOK-sEFnCqOtdVlbB0XcQGF32-8iGKS8UvmjE/edit") %>%
janitor::clean_names()
sheet <- read_sheet("https://docs.google.com/spreadsheets/d/1MJDXdoWOK-sEFnCqOtdVlbB0XcQGF32-8iGKS8UvmjE/edit") %>%
janitor::clean_names()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
dat <- df_s |>
group_by(states) |>
mutate(n_course_state = sum(n_each_course_state)) |>
mutate(state_n = paste(states, "<br/>", "<br/>",
"(Total Number of Training = ",
n_course_state,
")",
sep = ""))
state_name <- openxlsx::read.xlsx("data/States_codes_regions.xlsx") |>
janitor::clean_names()
dat <- dat |>
left_join(state_name,by = c("states"= "state_2"))
View(dat)
remove(dat)
dat <- df_s |>
group_by(states) |>
mutate(n_course_state = sum(n_each_course_state)) |>
mutate(state_n = paste(states, "<br/>", "<br/>",
"(Total Number of Training = ",
n_course_state,
")",
sep = ""))
dat <- df_s |>
group_by(states) |>
mutate(n_course_state = sum(n_each_course_state)) |>
mutate(state_n = paste(states, "<br/>", "<br/>",
"(Total Number of Training = ",
n_course_state,
")",
sep = ""))
dat <- df_s |>
group_by(states) |>
mutate(n_course_state = sum(n_each_course_state)) |>
mutate(state_n = paste(states, "<br/>", "<br/>",
"(Total Number of Training = ",
n_course_state,
")",
sep = ""))
state_name <- openxlsx::read.xlsx("data/States_codes_regions.xlsx") |>
janitor::clean_names()
dat <- dat |>
left_join(state_name,by = c("states"= "state_2")) |>
mutate(region_2 = ifelse(!is.na(region),
paste0("REGION ", as.roman(region)),
NA))
View(dat)
runApp()
# Import google sheet data and get authorization --------------------------
#gs4_auth() # get authentication
auth_url <- gargle::gargle_oauth_app_url()
# Import google sheet data and get authorization --------------------------
gs4_auth() # get authentication
test <- read_csv("data/Instructor-led Trainings Scheduling & Outreach - Scheduling.csv")
View(test)
View(sheet)
View(test)
View(dat)
View(sheet)
# Import google sheet data and get authorization --------------------------
gs4_auth() # get authentication
sheet <- read_sheet("https://docs.google.com/spreadsheets/d/1MJDXdoWOK-sEFnCqOtdVlbB0XcQGF32-8iGKS8UvmjE/edit") %>%
janitor::clean_names()
test <- read_csv("data/Instructor-led Trainings Scheduling & Outreach - Scheduling.csv")
View(test)
View(sheet)
View(test)
# unlist all cells
sheet_unlisted <- as.data.frame(sapply(sheet, function(col) {
sapply(col, function(cell) {
if(length(cell) > 0) cell[[1]] else NA
})
})) # The outer sapply iterates over the columns of the data frame df.
View(sheet)
sheet <- read_csv("data/Instructor-led Trainings Scheduling & Outreach - Scheduling.csv") %>%
janitor::clean_names()
col_index <- which(sheet[1, ] == "REMAINING")[1] # see where the word "remaining" is
sheet_selected <- sheet %>%
select(1:(col_index-1)) %>%  # select needed columns
filter(row_number() < which(training == "TOTAL")[1]) #select needed rows
View(sheet_selected)
## generate new column name based on the first row
new_col_name <- sapply(1:ncol(sheet_selected), function(i) {
val <- sheet_selected[1,i]
# Check for NA values
if (is.na(val)) {
return(names(sheet_selected)[i])
}
# Check for numbers from 1 to 10
if (str_detect(val, "^([1-9]|10)$")) {
return(paste0("region ", val))
} else {
return(names(sheet_selected)[i])
}
}) # if the row is number from 1-10 then use the number, otherwise copy the column name
colnames(sheet_selected) <- new_col_name
df_plotting <- sheet_selected %>%
slice(-1) %>% # remove the first row of the dataset
select("training", starts_with("region")) %>% # select training and region data
fill(!!names(sheet_selected)[1], .direction = "down") %>% #To fill NA values in the first column with the value from the row above
filter(str_detect(as.character(.[[1]]), "[0-9]"))
df_s <- df_plotting %>%
pivot_longer(cols = starts_with("region"),
names_to = "region",
values_to = "states"
)
df_s <- df_s %>%
select(training, states) %>%
na.omit() %>%
group_by(training, states) %>%
summarise(n_each_course_state = n())
View(df_s)
runApp()
rsconnect::deployApp
runApp()
here::here("Data Cleaning_csv.R")
here::here("data/fema_regions")
runApp()
here::here("Data Cleaning_csv.R")
runApp()
here::here("Data_Cleaning_csv.R")
runApp()
shiny::runApp()
test_dat <- read.csv("C:\Users\sh3685\Downloads\UserCourseTranscripts_2023-10-02-18-54-39.csv)
test_dat <- read.csv("C:\Users\sh3685\Downloads\UserCourseTranscripts_2023-10-02-18-54-39.csv")
test_dat <- read_csv("C:\Users\sh3685\Downloads\UserCourseTranscripts_2023-10-02-18-54-39.csv")
test_dat <- read_csv("C:\Users\sh3685\Downloads\UserCourseTranscripts_2023-10-02-18-54-39.csv")%>%
library(dplyr)
test_dat <- read_csv("C:\Users\sh3685\Downloads\UserCourseTranscripts_2023-10-02-18-54-39.csv")%>%
dat <- read_csv("C:\Users\sh3685\Downloads\UserCourseTranscripts_2023-10-02-18-54-39.csv")%>%
dat <- read_csv("C:\Users\sh3685\Desktop\Shuyang Huang\03_Project task\20231002_Save the previous LMS data\dat\UserCourseTranscripts_2023-10-02-18-54-39.csv")%>%
dat <- read_csv("C:/Users/sh3685/Desktop/Shuyang Huang/03_Project task/20231002_Save the previous LMS data/dat/UserCourseTranscripts_2023-10-02-18-54-39.csv") %>%
janitor::clean_names()
library(tidyverse)
dat <- read_csv("C:/Users/sh3685/Desktop/Shuyang Huang/03_Project task/20231002_Save the previous LMS data/dat/UserCourseTranscripts_2023-10-02-18-54-39.csv") %>%
janitor::clean_names()
summary(dat)
View(dat)
unique(dat$full_name)
summary(dat$full_name)
num_unique_values <- sapply(dat, function(x) length(unique(x)))
length(unique(dat))
length(unique(dat))
print(num_unique_values)
unique(dat$course)
unique(dat$module)
colnames(dat)
unique(dat$code)
shiny::runApp()
runApp()
runApp()
runApp()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(stringr)
library(qualtRics)
library(plotly)
# Get all surveys ID
surveys <- all_surveys()
# Get all surveys ID
surveys <- all_surveys()
# fetch the post test data
dat_post_test <- fetch_survey(surveyID = "SV_3EPGXCnwX6kkNo2",
verbose = TRUE,
label = FALSE,
convert = FALSE,
force_request = TRUE) %>%
janitor::clean_names()
# fetch the pre test data
dat_pre_test <- fetch_survey(surveyID = "SV_1zvXZxERYO2KBb8",
verbose = TRUE,
label = FALSE, # TRUE to export survey responses as Choice Text or FALSE to export survey responses as values.
convert = FALSE,
force_request = TRUE) %>%
janitor::clean_names()
PreTest <- dat_pre_test %>%
mutate_if(is.character, funs(na_if(., ""))) %>% # For each character column in the data frame, it will replace any empty strings with NA values.
mutate(sc0 = as.numeric(sc0)) %>%
filter(sc0!= 0) %>%
drop_na(qid13) %>% # get rid of the blank results
group_by(qid13) %>%
filter(sc0 == min(sc0)) %>%
filter(row_number()==1) %>%
ungroup() %>%  # get rid of the same ppl's multiple result
group_by(qid24) %>%
filter(sc0 == min(sc0)) %>%
filter(row_number()==1) %>%
ungroup() %>%  # get rid of the same ppl's multiple result
filter(grepl("@", qid24)) %>%
#filter(!qid24 %in% c("test@test.com", "heb2138@columbia.edu")) %>%
filter(!tolower(qid13) %in% c("jingjing", "test", "hannah"))
PreTest <- dat_pre_test %>%
mutate_if(is.character, funs(na_if(., ""))) %>% # For each character column in the data frame, it will replace any empty strings with NA values.
mutate(sc0 = as.numeric(sc0)) %>%
filter(sc0!= 0) %>%
drop_na(qid13) %>% # get rid of the blank results
group_by(qid13) %>%
filter(sc0 == min(sc0)) %>%
filter(row_number()==1) %>%
ungroup() %>%  # get rid of the same ppl's multiple result
group_by(qid24) %>%
filter(sc0 == min(sc0)) %>%
filter(row_number()==1) %>%
ungroup() %>%  # get rid of the same ppl's multiple result
filter(grepl("@", qid24)) %>%
#filter(!qid24 %in% c("test@test.com", "heb2138@columbia.edu")) %>%
filter(!tolower(qid13) %in% c("jingjing", "test", "hannah"))
PostTest <- dat_post_test %>%
mutate_if(is.character, funs(na_if(., ""))) %>% # For each character column in the data frame, it will replace any empty strings with NA values.
mutate(sc0 = as.numeric(sc0)) %>%
filter(sc0!= 0) %>%
drop_na(qid13) %>% # get rid of the blank results
group_by(qid13) %>%
filter(sc0 == min(sc0)) %>%
filter(row_number()==1) %>%
ungroup() %>%  # get rid of the same ppl's multiple result
group_by(qid24) %>%
filter(sc0 == min(sc0)) %>%
filter(row_number()==1) %>%
ungroup() %>%  # get rid of the same ppl's multiple result
filter(grepl("@", qid24)) %>%
#filter(!qid24 %in% c("test@test.com", "heb2138@columbia.edu")) %>%
filter(!tolower(qid13) %in% c("jingjing", "jingjing bao", "test"))
Standard <- c(6,1,5,4,4,1,4,1,3,2)
Standard <- c(6,1,5,4,4,1,4,1,3,2)
dat_post_test_TF <- PostTest %>% select(q1:q10)
for (i in 1:ncol(dat_post_test_TF)) {
dat_post_test_TF[,i] <- dat_post_test_TF[,i] == Standard[i]
}
dat_post_test_TF_s <- dat_post_test_TF %>% pivot_longer(cols = q1:q10, names_to = "question", values_to = "post_test_answer")
dat_post_test_TF_s <- dat_post_test_TF_s %>% group_by(question) %>%
summarise(post_test_answer = 1-mean(post_test_answer))
dat_post_test_TF_s <- dat_post_test_TF_s %>%
mutate(question = factor(question,
levels = paste("q", 1:10, sep = "")))
dat_pre_test_TF <- PreTest %>% select(q1:q10)
for (i in 1:ncol(dat_pre_test_TF)) {
dat_pre_test_TF[,i] <- dat_pre_test_TF[,i] == Standard[i]
}
dat_pre_test_TF_s <- dat_pre_test_TF %>% pivot_longer(cols = q1:q10, names_to = "question", values_to = "pre_test_answer")
dat_pre_test_TF_s <- dat_pre_test_TF_s %>% group_by(question) %>%
summarise(pre_test_answer = 1-mean(pre_test_answer))
dat_pre_test_TF_s <- dat_pre_test_TF_s %>%
mutate(question = factor(question,
levels = paste("q", 1:10, sep = "")))
dat_pre_post_test <- dat_pre_test_TF_s %>%
left_join(dat_post_test_TF_s, by = "question")
dat_pre_post_test <- dat_pre_post_test %>%
pivot_longer(
cols = pre_test_answer:post_test_answer,
names_to = "Test_type",
names_pattern = "(.*)_answer$",
values_to = "answer"
) %>%
mutate(Test_type = factor(Test_type,
levels = c("pre_test","post_test")))
dat_pre_post_test <- dat_pre_post_test %>%
pivot_longer(
cols = pre_test_answer:post_test_answer,
names_to = "Test_type",
names_pattern = "(.*)_answer$",
values_to = "answer"
) %>%
mutate(Test_type = factor(Test_type,
levels = c("pre_test","post_test")))
# Executive Summary
For MGT 488, the pre-test had a commendable average score above 80, while the average for the post-test was around 90. However, there was a notable drop in participants from the pre-test to the post-test, decreasing from 41 to 18 participants. One possible reason could be that the Qualtrics Survey Platform experienced technical difficulties during the period the post-test was being administered in this pilot.
Test_result <- ggplot(dat_pre_post_test) +
aes(x = question, y = answer, fill = Test_type) +
geom_col(position = "dodge") +
scale_fill_brewer(palette = "PuRd", direction = 1) +
labs(x = "\nQuestion No.", y = "False Rate\n", title = "PER409 Pre-test and Post-test false rate by question") +
theme_minimal()
Test_result
